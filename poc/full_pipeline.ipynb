{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "229a7e58-a141-4d2d-b893-2a0c1d865258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg Path: /opt/homebrew/bin/ffmpeg\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from pytubefix import YouTube\n",
    "from Katna.video import Video\n",
    "from Katna.writer import KeyFrameDiskWriter\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "client.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/opt/homebrew/bin/ffmpeg\"\n",
    "os.environ[\"FFMPEG_BINARY\"] = \"/opt/homebrew/bin/ffmpeg\"\n",
    "print(\"FFmpeg Path:\", os.environ[\"IMAGEIO_FFMPEG_EXE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8826e64-7ba4-45be-81f1-addb7d756afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(youtube_url, save_title, save_path=\"downloads/\"):\n",
    "    try:\n",
    "        yt = YouTube(youtube_url)\n",
    "        stream = yt.streams.get_highest_resolution()\n",
    "\n",
    "        print(f\"Downloading: {yt.title}\")\n",
    "        stream.download(output_path=save_path, filename=save_title)\n",
    "        print(f\"Downloaded successfully to {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afc1421-b73e-4af1-aa71-76d52a2f0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyframes(video_path, output_dir=\"output/selectedframes\", num_keyframes=3, ffmpeg_path=\"/opt/homebrew/bin/ffmpeg\"):\n",
    "    try:\n",
    "        os.environ[\"IMAGEIO_FFMPEG_EXE\"] = ffmpeg_path\n",
    "        os.environ[\"FFMPEG_BINARY\"] = ffmpeg_path\n",
    "        print(\"FFmpeg Path:\", os.environ[\"IMAGEIO_FFMPEG_EXE\"])\n",
    "\n",
    "        vd = Video()\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        diskwriter = KeyFrameDiskWriter(location=output_dir)\n",
    "\n",
    "        print(f\"Input video file path = {video_path}\")\n",
    "        print(f\"Output keyframes will be saved to: {output_dir}\")\n",
    "\n",
    "        vd.extract_video_keyframes(\n",
    "            no_of_frames=num_keyframes, file_path=video_path, writer=diskwriter\n",
    "        )\n",
    "\n",
    "        print(f\"Keyframes extracted and saved to {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during keyframe extraction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374347aa-89e7-4c80-83f1-c1a6cf2127f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(link):\n",
    "#     https://www.youtube.com/watch?v=nt63k3bfXS0&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=6\n",
    "    v = link.find(\"v=\")+2\n",
    "    video_id = link[v:v+11]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c923a796-1d49-4be5-bd37-de60839d3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_openai(transcript):\n",
    "    combined_text = \"\"\n",
    "    for segment in transcript:\n",
    "        start_time = segment['start'] / 60\n",
    "        combined_text += f\"[{start_time:.2f}] {segment['text']}\\n\"\n",
    "    return combined_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997899b5-1ddc-4bcd-82c4-c599c7411787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_transcript(text_to_summarize, model=\"gpt-4o-mini\"):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert at creating detailed, structured lecture notes from transcripts.\n",
    "\n",
    "    Your task is to convert the provided lecture transcript into comprehensive, well-organized, and insightful lecture notes, as well as provide timestamps that align with the video's original transcript.\n",
    "\n",
    "    TeX syntax should be utilized to explain and elaborate on the concepts within each subsection. Generate TeX inline math environments as necessary. \n",
    "    \n",
    "    Each set of notes should follow this format:\n",
    "    \n",
    "    # Lecture Notes on [Topic Name]\n",
    "    \n",
    "    ## Introduction\n",
    "    - Begin with a summary of the overall lecture and its goals.\n",
    "    \n",
    "    ## [Main Section Title]\n",
    "    ### Subsection 1\n",
    "    - Elaborate on the main point(s) of the subsection.\n",
    "    \n",
    "    ### Subsection 2\n",
    "    - Continue explaining and expanding.\n",
    "\n",
    "    ### Additional Analysis\n",
    "    - Expand on the original content, and write a paragraph or two that integrate your own expertise and insights. This should provide an extensive, educational resource on the subject.\n",
    "    \n",
    "    ## [Next Main Section Title]\n",
    "    - Organize subsequent sections similarly, ensuring a logical flow.\n",
    "    \n",
    "    ## Conclusion\n",
    "    - Summarize the lecture's key takeaways.\n",
    "    - Provide general advice or actionable insights related to the topic.\n",
    "    \n",
    "    ### General Tips\n",
    "    - Include any advice or practical steps relevant to understanding or applying the concepts.\n",
    "\n",
    "    Here is the lecture transcript:\n",
    "    \n",
    "    {text_to_summarize}\n",
    "\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": prompt}\n",
    "        ],\n",
    "        seed=0,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "# Generate the summary\n",
    "# summary = summarize_chunk(cleaned_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b853378-2fba-4e2f-a0c6-f99f93004f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_to_text(summarized, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(summarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fea3334-5a06-492c-b15d-aaa3a9117fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_for_latex(text):\n",
    "    special_chars = {\n",
    "        \"#\": r\"\\#\",\n",
    "        \"%\": r\"\\%\",\n",
    "        \"_\": r\"\\_\",\n",
    "        \"&\": r\"\\&\",\n",
    "        \"$\": r\"\\$\",\n",
    "    }\n",
    "    for char, replacement in special_chars.items():\n",
    "        text = text.replace(char, replacement)\n",
    "    return text\n",
    "\n",
    "\n",
    "def save_summary_to_latex(input_text, output_file):\n",
    "    # LaTeX preamble and document start\n",
    "    preamble = r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{amssymb}\n",
    "\\usepackage{geometry}\n",
    "\\usepackage{graphicx}\n",
    "\\geometry{margin=1in}\n",
    "\\usepackage{hyperref}\n",
    "\\hypersetup{\n",
    "    colorlinks=true,\n",
    "    linkcolor=blue,\n",
    "    filecolor=magenta,      \n",
    "    urlcolor=cyan,\n",
    "}\n",
    "\n",
    "\\title{Lecture Notes}\n",
    "\\author{}\n",
    "\\date{}\n",
    "\n",
    "\\begin{document}\n",
    "\\maketitle\n",
    "\"\"\"\n",
    "    end = r\"\\end{document}\"\n",
    "\n",
    "    # create headers\n",
    "    converted_text = re.sub(r\"^# (.+)$\", r\"\\\\section*{\\1}\", input_text, flags=re.MULTILINE)\n",
    "    converted_text = re.sub(r\"^## (.+)$\", r\"\\\\subsection*{\\1}\", converted_text, flags=re.MULTILINE)\n",
    "    converted_text = re.sub(r\"^### (.+)$\", r\"\\\\subsubsection*{\\1}\", converted_text, flags=re.MULTILINE)\n",
    "\n",
    "\n",
    "    # clean latex\n",
    "    converted_text = clean_for_latex(converted_text)\n",
    "\n",
    "    # fix bullet points\n",
    "    def wrap_itemize(match):\n",
    "        items = match.group(1).strip().split(\"\\n\")\n",
    "        formatted_items = \"\\n\".join([f\"\\\\item {item[2:].strip()}\" for item in items if item.strip()])\n",
    "        return f\"\\\\begin{{itemize}}\\n{formatted_items}\\n\\\\end{{itemize}}\"\n",
    "\n",
    "    converted_text = re.sub(r\"(?m)(^- .+(?:\\n- .+)*)\", wrap_itemize, converted_text)\n",
    "\n",
    "    # attempted fix for math environments but it doesn't really work\n",
    "    converted_text = re.sub(r\"\\\\\\[([^\\\\]+)\\\\\\]\", r\"\\\\[\\1\\\\]\", converted_text)\n",
    "    converted_text = re.sub(r\"\\\\\\((.+?)\\\\\\)\", r\"$\\1$\", converted_text)\n",
    "    #subscripts for math environment \n",
    "    converted_text = re.sub(r\"([a-zA-Z])_([a-zA-Z0-9]+)\", r\"{\\1_\\{\\2\\}}\", converted_text)\n",
    "    converted_text = re.sub(r\"([a-zA-Z])\\^([a-zA-Z0-9]+)\", r\"{\\1^\\{\\2\\}}\", converted_text)\n",
    "\n",
    "    latex_content = f\"{preamble}{converted_text}\\n{end}\"\n",
    "\n",
    "    with open(output_file, 'w') as tex_file:\n",
    "        tex_file.write(latex_content)\n",
    "\n",
    "    print(f\"LaTeX file '{output_file}' generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a713234-10b5-4122-b4c0-24b3f07a5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tex_to_pdf(tex_file, output_dir=None, keyframe_paths=[]):\n",
    "    if not tex_file.endswith(\".tex\"):\n",
    "        raise ValueError(\"Input file must be a .tex file\")\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.dirname(tex_file) or \".\"\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # add keyframes to top of file\n",
    "    with open(tex_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    keyframes_tex = \"\\n\".join(\n",
    "        f\"\\\\includegraphics[width=0.3\\\\textwidth]{{{path}}}\\\\hspace{{5mm}}\"\n",
    "        for path in keyframe_paths\n",
    "    )\n",
    "    keyframes_tex = f\"\\\\begin{{center}}\\n{keyframes_tex}\\n\\\\end{{center}}\\n\"\n",
    "    section_marker = r\"\\section*{\"\n",
    "    insert_position = content.find(section_marker)\n",
    "    if insert_position != -1:\n",
    "        # Find the end of the section header\n",
    "        section_end = content.find(\"}\", insert_position) + 1\n",
    "        content = content[:section_end] + \"\\n\" + keyframes_tex + content[section_end:]\n",
    "    else:\n",
    "        print(\"Warning: Section header not found. Keyframes will not be inserted under a section.\")\n",
    "    \n",
    "    with open(tex_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"pdflatex\", \"-interaction=nonstopmode\", \"-file-line-error\", \"-output-directory\", output_dir, tex_file],\n",
    "            check=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "        )\n",
    "        pdf_file = os.path.join(output_dir, os.path.basename(tex_file).replace(\".tex\", \".pdf\"))\n",
    "        if os.path.exists(pdf_file):\n",
    "            print(f\"PDF generated: {pdf_file}\")\n",
    "            return pdf_file\n",
    "        else:\n",
    "            raise FileNotFoundError(\"PDF generation failed. Check the LaTeX log for errors.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during LaTeX compilation:\")\n",
    "        print(e.stdout) \n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e685fcd-a9ed-45f2-8558-ff9928a46d3b",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4445bff3-f3c8-454a-8a06-95403a227bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(youtube_url, pdf_name, file_title, num_keyframes=3, save_title=\"video.mp4\", ffmpeg_path=\"/opt/homebrew/bin/ffmpeg\"):\n",
    "    \"\"\"\n",
    "    input: video url\n",
    "    output: summary of the video in pdf form with keyframes and intermediate files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define output directories\n",
    "        base_output_dir = f\"outputs/{pdf_name}\"\n",
    "        video_output_dir = f\"{base_output_dir}/downloads\"\n",
    "        keyframes_output_dir = f\"{base_output_dir}/keyframes\"\n",
    "        text_output_dir = f\"{base_output_dir}/texts\"\n",
    "        \n",
    "        # Ensure directories exist\n",
    "        os.makedirs(video_output_dir, exist_ok=True)\n",
    "        os.makedirs(keyframes_output_dir, exist_ok=True)\n",
    "        os.makedirs(text_output_dir, exist_ok=True)\n",
    "\n",
    "        # Step 1: Download video\n",
    "        save_path = os.path.join(video_output_dir, save_title)\n",
    "        print(\"Downloading video...\")\n",
    "        download_video(youtube_url, save_title, save_path=video_output_dir)\n",
    "\n",
    "        # Step 2: Extract keyframes\n",
    "        print(\"Extracting keyframes...\")\n",
    "        extract_keyframes(save_path, output_dir=keyframes_output_dir, num_keyframes=num_keyframes, ffmpeg_path=ffmpeg_path)\n",
    "\n",
    "        # Step 3: Fetch and process transcript\n",
    "        print(\"Fetching transcript...\")\n",
    "        transcript = get_transcript(youtube_url)\n",
    "        print(\"Processing transcript...\")\n",
    "        processed_transcript = preprocess_for_openai(transcript)\n",
    "\n",
    "        # Step 4: Summarize transcript\n",
    "        print(\"Summarizing transcript...\")\n",
    "        summarized = summarize_transcript(processed_transcript)\n",
    "        summarized = summarized.choices[0].message.content\n",
    "\n",
    "        # Step 5: Save summary to text\n",
    "        text_file_path = os.path.join(text_output_dir, f\"{file_title}.txt\")\n",
    "        print(\"Saving summary to text file...\")\n",
    "        save_summary_to_text(summarized, text_file_path)\n",
    "\n",
    "        # Step 6: Convert summary to LaTeX\n",
    "        tex_file_path = os.path.join(base_output_dir, f\"{file_title}.tex\")\n",
    "        print(\"Converting summary to LaTeX...\")\n",
    "        save_summary_to_latex(summarized, tex_file_path)\n",
    "\n",
    "        # Step 7: Prepare keyframe paths\n",
    "        keyframe_paths = [\n",
    "            os.path.join(keyframes_output_dir, filename)\n",
    "            for filename in sorted(os.listdir(keyframes_output_dir))\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "        print(f\"Found keyframes: {keyframe_paths}\")\n",
    "\n",
    "        # Step 8: Convert LaTeX to PDF\n",
    "        print(\"Converting LaTeX to PDF...\")\n",
    "        tex_to_pdf(tex_file_path, os.path.join(base_output_dir, file_title), keyframe_paths = keyframe_paths)\n",
    "\n",
    "        print(\"Pipeline completed successfully! All outputs saved in:\", base_output_dir)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in pipeline: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e33f1cdc-2122-4dc4-96f7-99ec87cbe9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video...\n",
      "Downloading: Lecture #1: Introduction â€” Brandon Sanderson on Writing Science Fiction and Fantasy\n",
      "Downloaded successfully to outputs/brandon_sanderson_vid/downloads\n",
      "Extracting keyframes...\n",
      "FFmpeg Path: /opt/homebrew/bin/ffmpeg\n",
      "Input video file path = outputs/brandon_sanderson_vid/downloads/video.mp4\n",
      "Output keyframes will be saved to: outputs/brandon_sanderson_vid/keyframes\n",
      "Large Video (duration = 64 min), will split into smaller videos \n",
      "Video split complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing for :  outputs/brandon_sanderson_vid/downloads/video.mp4\n",
      "Keyframes extracted and saved to outputs/brandon_sanderson_vid/keyframes\n",
      "Fetching transcript...\n",
      "Processing transcript...\n",
      "Summarizing transcript...\n",
      "Saving summary to text file...\n",
      "Converting summary to LaTeX...\n",
      "LaTeX file 'outputs/brandon_sanderson_vid/brandon_sanderson_lecture.tex' generated successfully.\n",
      "Found keyframes: ['outputs/brandon_sanderson_vid/keyframes/video_0.jpeg', 'outputs/brandon_sanderson_vid/keyframes/video_1.jpeg', 'outputs/brandon_sanderson_vid/keyframes/video_2.jpeg']\n",
      "Converting LaTeX to PDF...\n",
      "PDF generated: outputs/brandon_sanderson_vid/brandon_sanderson_lecture/brandon_sanderson_lecture.pdf\n",
      "Pipeline completed successfully! All outputs saved in: outputs/brandon_sanderson_vid\n"
     ]
    }
   ],
   "source": [
    "pipeline(\"https://www.youtube.com/watch?v=-6HOdHEeosc\", \"brandon_sanderson_vid\", \"brandon_sanderson_lecture\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
